{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[IGTI]NLP -  ALUNO - ATIVIDADE PRÁTICA  - CLASSIFICAÇÃO DE TEXTO USANDO MACHINE LEARNING",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP -  ATIVIDADE PRÁTICA  - CLASSIFICAÇÃO DE TEXTO USANDO MACHINE LEARNING"
      ],
      "metadata": {
        "id": "7LSftkX8MJzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta prática iremos classificar um texto a partir de algoritmos de classificação e implementar um Random Forest. Para resolução do problema de classificação, passaremos por algumas etapas, conforme discutido em nossos estudos.\n",
        "\n",
        "## O que é classificação de texto?\n",
        "A Classificação de Texto é um processo automatizado de classificação em categorias predefinidas. Podemos classificar e-mails em spam ou não spam, artigos de notícias em diferentes categorias, como política, mercado de ações, esportes, etc.\n",
        "\n",
        "Isso pode ser feito com a ajuda de Processamento de Linguagem Natural e diferentes Algoritmos de Classificação como Naive Bayes, SVM e até Redes Neurais em Python.\n",
        "\n",
        "Usaremos o conjunto de dados de reviews da Amazon que possui 10.000 linhas de dados de texto classificados em “Rótulo 1” e “Rótulo 2”. O conjunto de dados tem duas colunas “Texto” e “Rótulo”. Você pode baixar os dados em https://raw.githubusercontent.com/Gunjitbedi/Text-Classification/master/corpus.csv ."
      ],
      "metadata": {
        "id": "AVAINdM7shUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importar bibliotecas\n"
      ],
      "metadata": {
        "id": "fdCmbno5Mkx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7-58Q-MJNl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\"\"\" \n",
        "PERGUNTA 1 \n",
        "Insira os modulos do NLTK para fazer download\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir sementes aleatórias\n",
        "\n",
        "Isso é usado para reproduzir o mesmo resultado todas as vezes se o script for mantido consistente, caso contrário, cada execução produzirá resultados diferentes. A semente pode ser definida para qualquer número."
      ],
      "metadata": {
        "id": "bTHlExp1pZBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "PERGUNTA 2 \n",
        "A definição de sementes aleatórias pode ser definida pelo seguinte código\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "kHgLOOExpZso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adicionando o corpus"
      ],
      "metadata": {
        "id": "G2oXpxLar3Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive and past the correct path for read ther corpus\n",
        "'''\n",
        "OBS: Você deve conectar o Notebook ao seu drive pessoal e indicar o caminho correto para acesso ao dataset corpus.csv\n",
        "'''\n",
        "### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "6tMmBbJcr5Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "PERGUNTA 3\n",
        "Qual o tipo de dados da variável Corpus criada?\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "rexeZ6DuOELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre processamento\n",
        "Transformar dados brutos em um formato compreensível para modelos de PLN. Os dados do mundo real geralmente são incompletos, inconsistentes e provavelmente contêm muitos erros. O pré-processamento de dados é um método comprovado de resolver esses problemas. Isso ajudará na obtenção de melhores resultados por meio dos algoritmos de classificação."
      ],
      "metadata": {
        "id": "v4h8ha7ssIXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERGUNTA 4\n",
        "Para remover linhas em brancos se houver, usamos o seguinte trecho de codigo:\n",
        "\"\"\"\n",
        "# Step - a: Remove blank rows if any.\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "\"\"\"\n",
        "PERGUNTA 5\n",
        "Para passar todo o texto para letras minusculas, usamos o seguinte trecho de codigo:\n",
        "\"\"\"\n",
        "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "\"\"\"\n",
        "PERGUNTA 6\n",
        "Para quebrar o corpus em um conjunto de palavras, usamos o seguinte trecho de código:\n",
        "\"\"\"\n",
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "\"\"\"\n",
        "PERGUNTA 7\n",
        "Para fazermos o mapa de taggeamento das palavras em Adjetivo, Verbo e Adverbio, usamos o seguinte trecho de código:\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "for index,entry in enumerate(Corpus['text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    \"\"\"\n",
        "    PERGUNTA 8\n",
        "    Para iniciar o WordNet lemmatizer, usamos o seguinte trecho de código:\n",
        "    \"\"\"\n",
        "    ### SEU CODIGO AQUI ###\n",
        "    \n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    Corpus.loc[index,'text_final'] = str(Final_words)"
      ],
      "metadata": {
        "id": "D1gtW-gbLprK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparar o conjunto de treino e teste"
      ],
      "metadata": {
        "id": "bUTGIuavOSmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERGUNTA 9\n",
        "Para separar o conjunto entre treino e teste com 70% para treino e 30% para teste, usamos o seguinte trecho de código:\n",
        "\"\"\"\n",
        "Train_X, Test_X, Train_Y, Test_Y = ### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "1dh3A_ydOczp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codificação\n",
        "Codificar rótulos (labels) na variável de destino — Isso é feito para transformar dados categóricos do tipo string no conjunto de dados em valores numéricos que o modelo pode entender."
      ],
      "metadata": {
        "id": "0qBM4whpOmHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERGUNTA 10\n",
        "Para transformar dados categóricos do tipo string no conjunto de dados em valores numéricos que o modelo pode entender,\n",
        "usamos o seguinte trecho de código:\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "metadata": {
        "id": "6QgoYgs1O8tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vetorização de palavras\n",
        "É um processo geral de transformar uma coleção de documentos de texto em vetores de recursos numéricos. Existem muitos métodos para converter dados de texto em vetores que o modelo pode entender, mas de longe o método mais popular é chamado TF-IDF. Este é um acrônimo que significa “Frequência de Termo – Documento Inverso” Frequência que são os componentes das pontuações resultantes atribuídas a cada palavra.\n",
        "\n",
        "> **Term Frequency:** resume a frequência com que uma determinada palavra aparece em um documento.\n",
        "\n",
        "> **Inverse Document Frequency:** Isso reduz as palavras que aparecem muito nos documentos.\n",
        "\n",
        "Sem entrar na matemática, TF-IDF são pontuações de frequência de palavras que tentam destacar palavras que são mais interessantes, por exemplo, frequentes em um documento, mas não em todos os documentos.\n",
        "\n",
        "A sintaxe a seguir pode ser usada para ajustar primeiro o modelo TF-IDF em todo o corpus. Isso ajudará o TF-IDF a construir um vocabulário de palavras que aprendeu com os dados do corpus e atribuirá um número inteiro único a cada uma dessas palavras. Serão no máximo 5000 palavras/características únicas, pois definimos o parâmetro max_features=5000.\n",
        "\n",
        "Finalmente vamos transformar Train_X e Test_X para Train_X_Tfidf vetorizado e Test_X_Tfidf . Estes agora conterão para cada linha uma lista de números inteiros exclusivos e sua importância associada conforme calculado pelo TF-IDF."
      ],
      "metadata": {
        "id": "EkQSD_-FPLD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PERGUNTA 10\n",
        "Ao utilizar o TF-IDF, com o tamanho máximo do vocabulário definido em 5000, qual trecho de código devemos utilizar?\n",
        "\"\"\"\n",
        "### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "DjIvQeEgQKBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ver o vocabulário aprendido com o Corpus"
      ],
      "metadata": {
        "id": "1UOY58Q8QNd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PERGUNTA 11 \n",
        "Para sabermos qual o vocabulário aprendido pelo Corpus, usamos usamos o seguinte trecho de código:\n",
        "O que esse vocabulário representa e qual é o seu tipo?\n",
        "'''\n",
        "### SEU CODIGO AQUI ###"
      ],
      "metadata": {
        "id": "EhsnNyqBQcro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir diretamente os dados vetorizados para ver como fica\n",
        "\n",
        "> **Saída:** — 1: Número da linha de 'Train_X_Tfidf', 2: Número inteiro único de cada palavra na primeira linha, 3: Pontuação calculada pelo TF-IDF Vectorizer\n",
        "\n"
      ],
      "metadata": {
        "id": "Wu7o6M2OQliL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_X_Tfidf)"
      ],
      "metadata": {
        "id": "UHYaieqhQczQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dessa forma, os conjuntos de dados estão prontos para serem alimentados em diferentes algoritmos de classificação."
      ],
      "metadata": {
        "id": "IwVhzMXGQ-Ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmos de ML para prever o resultado\n",
        "### Naive Bayes\n"
      ],
      "metadata": {
        "id": "Cj9x5G_BRJLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificador - Algoritmo - NB\n",
        "# ajuste o conjunto de dados de treinamento no classificador NB \n",
        "Naive = naive_bayes.MultinomialNB() \n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# prever os rótulos no conjunto de dados de validação \n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use a função precision_score para obter a precisão \n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "metadata": {
        "id": "YJLhOmX-RZuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "gfx7as2URlfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificador - Algoritmo - SVM \n",
        "# ajusta o conjunto de dados de treinamento no classificador \n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto') \n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# prever os rótulos no conjunto de dados de validação \n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use a função precision_score para obter a precisão \n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "metadata": {
        "id": "oRL4412DRtjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "j_M1z59W1KvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Com base na documentação do Scikilearn e dos algoritmos Naive Bayes e SVM apresentados em nossas aulas, codifique um classificador Random Forest \n",
        "(consulte a documentação do Scikit-learn e tome como exemplo os classificadores Naive Bayes e SVM implementados no Notebook) e responda as seguintes questões:\n",
        "\n",
        "PERGUNTA 12\n",
        "Considerando os valores de (n_estimators = 10, random_state = 0) e o conjunto de treino e\n",
        "teste como 70/30, o Random Forest teve a sua acurácia prevista na faixa de qual porcentagem?\n",
        "\n",
        "PERGUNTA 13\n",
        "Considerando os valores de (n_estimators = 100, random_state = 0) e o conjunto de treino e teste como 80/20, \n",
        "o Random Forest, Naive Bayes e SVM, em relação a acurácia obtida, marque a alternativa correta...\n",
        "\n",
        "PERGUNTA 14\n",
        "Considerando os valores de (n_estimators = 100, random_state = 0) e o conjunto de treino e teste como 80/20 \n",
        "em relação ao Random Forest, a seguinte afirmação está correta...\n",
        "\n",
        "PERGUNTA 15\n",
        "Pensando na perspectiva de melhoria dos modelos de Machine Learning, podemos avaliar o ajuste de hiper parâmetros, considerando as seguintes técnicas...\n",
        "\n",
        "\n",
        "PARA SE PENSAR...\n",
        "Como saber se o nosso modelo criado está generalizando de maneira adequada?\n",
        "\n",
        "- A base possui um tamanho adequado?\n",
        "- O classificador é adequado para o problema em questão?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Classificador - Algoritmo - RF\n",
        "# Needed for the next step in model parameter tuning\n",
        "Train_X, Test_X, Train_Y, Test_Y\n",
        "\n",
        "# random forest test\n",
        "# Instantiate classifier\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "# fit on training data\n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "# prever os rótulos no conjunto de dados de validação \n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "# Use a função precision_score para obter a precisão \n",
        "### SEU CODIGO AQUI ###\n",
        "\n",
        "# Seeing the metrics\n",
        "#print(\"Accuracy on training set: {:.3f}\".format(forest.score(Train_X_Tfidf,Train_Y)))\n",
        "#print(\"Accuracy on test set: {:.3f}\".format(forest.score(Test_X_Tfidf, Test_Y)))"
      ],
      "metadata": {
        "id": "Uw2suLbb1KSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}